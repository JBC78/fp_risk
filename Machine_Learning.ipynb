{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import joblib\r\n",
    "import pandas as pd\r\n",
    "import nltk\r\n",
    "nltk.download('punkt')\r\n",
    "nltk.download('stopwords')\r\n",
    "nltk.download('wordnet')\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "# Multinomial Naive Bayes Classifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "\r\n",
    "# Import Tf-idf Vectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "\r\n",
    "# Import the Label Encoder\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "\r\n",
    "# Import the train test split\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# To evaluate our model\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import roc_curve, auc\r\n",
    "from sklearn.metrics import roc_auc_score"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\joshu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv(\"Resources/Work_Contacts.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.head()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Date Observation Time Purchase Order Number RCS Number  \\\n",
       "0  5/07/2021          8:35:00             7154232cs      85039   \n",
       "1  5/07/2021          8:45:00               7190673        NaN   \n",
       "2  5/07/2021          8:50:00               7181286      90145   \n",
       "3  5/07/2021         11:49:00               7180602        NaN   \n",
       "4  5/07/2021         13:00:00               7180602        NaN   \n",
       "\n",
       "  Work Order Number Job Start Time Job Finish Time Work group  Risk  OC  \\\n",
       "0               NaN        8:30:00             NaN     Dartla  High   1   \n",
       "1               NaN        8:00:00             NaN  Awayclean  High   1   \n",
       "2               NaN        8:00:00             NaN  Awayclean  High   1   \n",
       "3               NaN       11:00:00        12:00:00  Awayclean  High   1   \n",
       "4               NaN       13:00:00        14:00:00  Awayclean  High   1   \n",
       "\n",
       "               Authority To Proceed Description  \\\n",
       "0                     Repair insulation PFT #31   \n",
       "1                             Bog out lake duck   \n",
       "2                          HPW clean vent lines   \n",
       "3  108w drain. vacuum out pit. N/E. of car park   \n",
       "4  108w drain. vacuum out pit. N/W. of car park   \n",
       "\n",
       "  Does ARP walk the job. In the alloted time frames  \\\n",
       "0                                                No   \n",
       "1                                                No   \n",
       "2                                                No   \n",
       "3                                                No   \n",
       "4                                                No   \n",
       "\n",
       "  Field Verifications Completed (ARP) Field Verifications Completed (CRP)  \\\n",
       "0                                 Yes                                 Yes   \n",
       "1                                 Yes                                 Yes   \n",
       "2                                 Yes                                 Yes   \n",
       "3                                 Yes                                 Yes   \n",
       "4                                 Yes                                 Yes   \n",
       "\n",
       "  Supervision Present  Total number of people on job  \n",
       "0                  No                              2  \n",
       "1                  No                              2  \n",
       "2                  No                              2  \n",
       "3                  No                              2  \n",
       "4                  No                              4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Observation Time</th>\n",
       "      <th>Purchase Order Number</th>\n",
       "      <th>RCS Number</th>\n",
       "      <th>Work Order Number</th>\n",
       "      <th>Job Start Time</th>\n",
       "      <th>Job Finish Time</th>\n",
       "      <th>Work group</th>\n",
       "      <th>Risk</th>\n",
       "      <th>OC</th>\n",
       "      <th>Authority To Proceed Description</th>\n",
       "      <th>Does ARP walk the job. In the alloted time frames</th>\n",
       "      <th>Field Verifications Completed (ARP)</th>\n",
       "      <th>Field Verifications Completed (CRP)</th>\n",
       "      <th>Supervision Present</th>\n",
       "      <th>Total number of people on job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/07/2021</td>\n",
       "      <td>8:35:00</td>\n",
       "      <td>7154232cs</td>\n",
       "      <td>85039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dartla</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>Repair insulation PFT #31</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/07/2021</td>\n",
       "      <td>8:45:00</td>\n",
       "      <td>7190673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awayclean</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>Bog out lake duck</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/07/2021</td>\n",
       "      <td>8:50:00</td>\n",
       "      <td>7181286</td>\n",
       "      <td>90145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awayclean</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>HPW clean vent lines</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/07/2021</td>\n",
       "      <td>11:49:00</td>\n",
       "      <td>7180602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>Awayclean</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>108w drain. vacuum out pit. N/E. of car park</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/07/2021</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>7180602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13:00:00</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>Awayclean</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>108w drain. vacuum out pit. N/W. of car park</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_clean = df[['Risk', 'Authority To Proceed Description']]\r\n",
    "df_clean = df_clean.dropna()\r\n",
    "df_clean['Risk'] = df_clean['Risk'].str.lower()\r\n",
    "df_clean.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Risk              Authority To Proceed Description\n",
       "0  high                     Repair insulation PFT #31\n",
       "1  high                             Bog out lake duck\n",
       "2  high                          HPW clean vent lines\n",
       "3  high  108w drain. vacuum out pit. N/E. of car park\n",
       "4  high  108w drain. vacuum out pit. N/W. of car park"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Risk</th>\n",
       "      <th>Authority To Proceed Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>Repair insulation PFT #31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>Bog out lake duck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>HPW clean vent lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>108w drain. vacuum out pit. N/E. of car park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>108w drain. vacuum out pit. N/W. of car park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Make the letters lower case and tokenize the words\r\n",
    "tokenized_messages = df_clean['Authority To Proceed Description'].str.lower().apply(word_tokenize)\r\n",
    "\r\n",
    "# Print the tokens to see how it looks like\r\n",
    "print(tokenized_messages)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                       [repair, insulation, pft, #, 31]\n",
      "1                                 [bog, out, lake, duck]\n",
      "2                              [hpw, clean, vent, lines]\n",
      "3      [108w, drain, ., vacuum, out, pit, ., n/e, ., ...\n",
      "4      [108w, drain, ., vacuum, out, pit, ., n/w, ., ...\n",
      "                             ...                        \n",
      "297                        [rewire, vtat, transportable]\n",
      "298             [earth, works, on, potable, water, line]\n",
      "299                   [earthworks, potable, water, line]\n",
      "300                       [repair, potable, water, line]\n",
      "301                                  [build, sand, bund]\n",
      "Name: Authority To Proceed Description, Length: 302, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Define a function to returns only alphanumeric tokens\r\n",
    "def alpha(tokens):\r\n",
    "    \"\"\"This function removes all non-alphanumeric characters\"\"\"\r\n",
    "    alpha = []\r\n",
    "    for token in tokens:\r\n",
    "        if str.isalpha(token) or token in ['n\\'t','won\\'t']:\r\n",
    "            if token=='n\\'t':\r\n",
    "                alpha.append('not')\r\n",
    "                continue\r\n",
    "            elif token == 'won\\'t':\r\n",
    "                alpha.append('wont')\r\n",
    "                continue\r\n",
    "            alpha.append(token)\r\n",
    "    return alpha\r\n",
    "\r\n",
    "# Apply our function to tokens\r\n",
    "tokenized_messages = tokenized_messages.apply(alpha)\r\n",
    "\r\n",
    "print(tokenized_messages)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                     [repair, insulation, pft]\n",
      "1                        [bog, out, lake, duck]\n",
      "2                     [hpw, clean, vent, lines]\n",
      "3      [drain, vacuum, out, pit, of, car, park]\n",
      "4      [drain, vacuum, out, pit, of, car, park]\n",
      "                         ...                   \n",
      "297               [rewire, vtat, transportable]\n",
      "298    [earth, works, on, potable, water, line]\n",
      "299          [earthworks, potable, water, line]\n",
      "300              [repair, potable, water, line]\n",
      "301                         [build, sand, bund]\n",
      "Name: Authority To Proceed Description, Length: 302, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Define a function to remove stop words\r\n",
    "def remove_stop_words(tokens):\r\n",
    "    \"\"\"This function removes all stop words in terms of nltk stopwords\"\"\"\r\n",
    "    no_stop = []\r\n",
    "    for token in tokens:\r\n",
    "        if token not in stopwords.words('english'):\r\n",
    "            no_stop.append(token)\r\n",
    "    return no_stop\r\n",
    "\r\n",
    "# Apply our function to tokens\r\n",
    "tokenized_messages = tokenized_messages.apply(remove_stop_words)\r\n",
    "\r\n",
    "print(tokenized_messages)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0                 [repair, insulation, pft]\n",
      "1                         [bog, lake, duck]\n",
      "2                 [hpw, clean, vent, lines]\n",
      "3           [drain, vacuum, pit, car, park]\n",
      "4           [drain, vacuum, pit, car, park]\n",
      "                       ...                 \n",
      "297           [rewire, vtat, transportable]\n",
      "298    [earth, works, potable, water, line]\n",
      "299      [earthworks, potable, water, line]\n",
      "300          [repair, potable, water, line]\n",
      "301                     [build, sand, bund]\n",
      "Name: Authority To Proceed Description, Length: 302, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Define a function to lemmatization\r\n",
    "def lemmatize(tokens):\r\n",
    "    \"\"\"This function lemmatize the messages\"\"\"\r\n",
    "    # Initialize the WordNetLemmatizer\r\n",
    "    lemmatizer = WordNetLemmatizer()\r\n",
    "    # Create the lemmatized list\r\n",
    "    lemmatized = []\r\n",
    "    for token in tokens:\r\n",
    "            # Lemmatize and append\r\n",
    "            lemmatized.append(lemmatizer.lemmatize(token))\r\n",
    "    return \" \".join(lemmatized)\r\n",
    "\r\n",
    "# Apply our function to tokens\r\n",
    "tokenized_messages = tokenized_messages.apply(lemmatize)\r\n",
    "\r\n",
    "print(tokenized_messages)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0              repair insulation pft\n",
      "1                      bog lake duck\n",
      "2                hpw clean vent line\n",
      "3          drain vacuum pit car park\n",
      "4          drain vacuum pit car park\n",
      "                   ...              \n",
      "297        rewire vtat transportable\n",
      "298    earth work potable water line\n",
      "299     earthwork potable water line\n",
      "300        repair potable water line\n",
      "301                  build sand bund\n",
      "Name: Authority To Proceed Description, Length: 302, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Replace the columns with tokenized messages\r\n",
    "df_clean['Authority To Proceed Description'] = tokenized_messages\r\n",
    "\r\n",
    "# Display the first five rows\r\n",
    "df_clean.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Risk Authority To Proceed Description\n",
       "0  high            repair insulation pft\n",
       "1  high                    bog lake duck\n",
       "2  high              hpw clean vent line\n",
       "3  high        drain vacuum pit car park\n",
       "4  high        drain vacuum pit car park"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Risk</th>\n",
       "      <th>Authority To Proceed Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>repair insulation pft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>bog lake duck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>hpw clean vent line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>drain vacuum pit car park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>drain vacuum pit car park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "labelEncoder = LabelEncoder()\r\n",
    "df_clean = df_clean.sort_values(\"Risk\", ignore_index=True)\r\n",
    "df_clean['risk_encoded'] = labelEncoder.fit_transform(df_clean['Risk']) #Identify unique values\r\n",
    "df_clean.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Risk Authority To Proceed Description  risk_encoded\n",
       "0  high            repair insulation pft             0\n",
       "1  high        splice mill feed conveyor             0\n",
       "2  high        splice mill feed conveyor             0\n",
       "3  high                  routine testing             0\n",
       "4  high         replace dsm segment mill             0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Risk</th>\n",
       "      <th>Authority To Proceed Description</th>\n",
       "      <th>risk_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high</td>\n",
       "      <td>repair insulation pft</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>splice mill feed conveyor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>splice mill feed conveyor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high</td>\n",
       "      <td>routine testing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>replace dsm segment mill</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Select the features and the target\r\n",
    "X = df_clean['Authority To Proceed Description']\r\n",
    "y = df_clean['risk_encoded']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Create the tf-idf vectorizer\r\n",
    "vectorizer = TfidfVectorizer(strip_accents='ascii')\r\n",
    "\r\n",
    "# First fit the vectorizer with our training set\r\n",
    "tfidf_train = vectorizer.fit_transform(X_train)\r\n",
    "\r\n",
    "# Now we can fit our test data with the same vectorizer\r\n",
    "tfidf_test = vectorizer.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Initialize the Multinomial Naive Bayes classifier\r\n",
    "nb = MultinomialNB()\r\n",
    "\r\n",
    "# Fit the model\r\n",
    "nb.fit(tfidf_train, y_train)\r\n",
    "\r\n",
    "# Print the accuracy score\r\n",
    "print(\"Accuracy:\",nb.score(tfidf_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.9180327868852459\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "y_predicted = nb.predict(tfidf_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "y_predicted"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 2, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       2, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "test_results = pd.DataFrame({\r\n",
    "    \"Actual\":y_test,\r\n",
    "    \"Predicted\":y_predicted\r\n",
    "})\r\n",
    "test_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Actual  Predicted\n",
       "56        0          0\n",
       "296       2          2\n",
       "290       2          2\n",
       "170       0          0\n",
       "74        0          2\n",
       "..      ...        ...\n",
       "293       2          2\n",
       "128       0          0\n",
       "228       2          2\n",
       "28        0          0\n",
       "40        0          0\n",
       "\n",
       "[61 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "df_clean[[\"Risk\", \"risk_encoded\"]].groupby([\"Risk\", \"risk_encoded\"]).count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(high, 0), (low, 1), (medium, 2)]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk</th>\n",
       "      <th>risk_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "joblib.dump(nb,'naive_bayes.pkl')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['naive_bayes.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "joblib.dump(vectorizer, \"vectorizer.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('PythonData': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "interpreter": {
   "hash": "cc6b640b07428b914d62f39a3a5ea291fe2d47be89d66ff8806ca179544c7ade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}